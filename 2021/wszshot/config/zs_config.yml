device: cuda


global_macros:
  # =============== George washington dataset ===============
  - _GW_BASE: &GW_BASE /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/
  # Image directories
  - _GW_train_img: &GW_train_img [/media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV1_train, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV2_train, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV3_train, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV4_train]
  - _GW_valid_img: &GW_valid_img [/media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV1_valid, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV2_valid, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV3_valid, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV4_valid]
  - _GW_test_img: &GW_test_img [/media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV1_test, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV2_test, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV3_test, /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/GW_Data/CV4_test]
  # Word labels

  # =============== IAM dataset ===============
  - _IAM_BASE: &IAM_BASE /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/
  # Image directories
  - _IAM_train_img: &IAM_train_img /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_train
  - _IAM_valid_img: &IAM_valid_img /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_valid
  - _IAM_test_img: &IAM_test_img /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_test
  # Word labels
  - _IAM_train_word_labels: &IAM_train_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_train.csv
  - _IAM_valid_word_labels: &IAM_valid_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_valid.csv
  - _IAM_valid_seen_word_labels: &IAM_valid_seen_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_valid_seen.csv
  - _IAM_valid_unseen_word_labels: &IAM_valid_unseen_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_valid_unseen.csv
  - _IAM_test_seen_word_labels: &IAM_test_seen_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_test_seen.csv
  - _IAM_test_unseen_word_labels: &IAM_test_unseen_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_test_unseen.csv
  # data base files to accumulate input files
  - _IAM_train_db: &IAM_train_db /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_train.lmdb
  - _IAM_valid_db: &IAM_valid_db /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_valid.lmdb
  - _IAM_test_db: &IAM_test_db /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data/IAM_test.lmdb

# =============== IAM small dataset ===============
  - _IAM_BASE_by5: &IAM_BASE_by5 /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data_3_2_by5/
  # Image directories
  - _IAM_train_img_by5: &IAM_train_img_by5 /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data_3_2_by5/train
  - _IAM_valid_img_by5: &IAM_valid_img_by5 /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data_3_2_by5/valid
  # Word labels
  - _IAM_train_word_labels_by5: &IAM_train_word_labels_by5 /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data_3_2_by5/iam_by5_train.csv
  - _IAM_valid_word_labels_by5: &IAM_valid_word_labels_by5 /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/IAM_Data_3_2_by5/iam_by5_valid.csv
  
  # =============== Unit test dataset ===============
  - _UT_BASE: &UT_BASE /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data
  # Image directories
  - _UT_train_img: &UT_train_img /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data/train
  - _UT_valid_img: &UT_valid_img /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data/val
  # Word labels
  - _UT_train_word_labels: &UT_train_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data/train.csv
  - _UT_valid_word_labels: &UT_valid_word_labels /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data/val.csv
  # data base files to accumulate input files
  - _UT_train_db: &UT_train_db /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data/train.lmdb
  - _UT_valid_db: &UT_valid_db /media/windowsC/SIN_Desktop/projects/ZSL_WordSpotting/unit_test_data/val.lmdb

loaders:
  dataset_config:
    general:
      ds_class: [utils.dataset.phosc.PHOSCZSDataset, 
      utils.dataset.phosc.ImageDataset, 
      utils.dataset.phosc.PhosDataset, 
      utils.dataset.phosc.PhocDataset,
      utils.dataset.phosc.WordlabelDataset]
      type: dir # dir/lmdb/df/h5 if none: pick images from folders
      # Specify paths to db/data/labels
      raw: null
      label: null
      unseen: null
    train:
      raw: *IAM_train_img
      label: *IAM_train_word_labels
    valid:
      raw: *IAM_valid_img
      label: *IAM_valid_word_labels
  
  loader_config:
    utils.dataloader.phosc.PHOSCZSDataModule:
      seed: 1234
      drop_last: True
      pin_memory: True
      shuffle: True
      batch_size: 32
      num_workers: 10

model:
  models.phocnet.PHOSCNet:
    conv:
      in_ch: 3
      fmaps: [64, 128, 256, 256, 256, 512]
      kernel_size: 3
      stride: 1
      padding: 1
      layer_order: cr
      last_single_conv_fmap: 512
    pool:
      layer_index: [1, 3] # layer index where MaxPooling is required. Note indexing starts from 0
      kernel_size: 2
      stride: 2
      padding: 0
    pyramid_pooling:
      type: spatial
      levels: [1, 2, 4]
    phos_head:
        fmaps: [4096, 4096, 165]
        dropout: [0.5, 0.5]
    phoc_head:
        fmaps: [4096, 4096, 604]
        dropout: [0.5, 0.5]

criterion:
  losses:
    phos:
      weight: 1.5
      pred_idx: 'phos'
      target_idx: 'phos'
      function: models.loss.phosc.PhosLoss

    phoc:
      weight: 4.5
      pred_idx: 'phoc'
      target_idx: 'phoc'
      function: models.loss.phosc.PhocLoss

  sum_loss:
    grad_stats: ['norm', 'max', 'mean']
    split_pred: True
    split_target: True

metric:
  name: models.metric.wsmetric.WSMetric

trainer:
  max_epochs: 10000 # basically infinite
  num_tile_col: 8

  optimizer:
    name: Adam
    lr: 1.0e-4
    betas: [0.9, 0.999]

  intervals:
    log_train_every: 128
    log_valid_every: 128
    validate_every: 128
    validate_for: 32
    
  #tensorboard:
  # log_scalars_every: [1, 'iterations']
  # log_images_every: [500, 'iterations']
  # send_volume_at_z_indices: 'mid'
  # split_config_keys: True
  # log_anywhere: ['scalars']

  callbacks:
    gradients:
      LogOutputGradients:
        frequency: 1

    essentials:
      GradientClip:
        clip_value: 1e-3

    scheduling:
      AutoLR:
        monitor: 'validation_loss'
        factor: 0.2
        patience: '5000 iterations'
        monitor_while: 'validating'
        monitor_momentum: 0.9
        cooldown_duration: '50000 iterations'
        consider_improvement_with_respect_to: 'previous'
        verbose: True
